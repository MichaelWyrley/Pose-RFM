# Diverse Pose Generation using Riemanian Flow Matching

This Project aims to generate a diverse set of poses through the use of Riemanian Flow Matching.

<!-- ![Pose](docs/out.mp4) -->
<figure class="video_container">
  <iframe src="docs/out.mp4" frameborder="0"> 
</iframe>
</figure>

## Project File Structure

```
github_root
└───dataset
│   └───3DPW
│   └───amass
│   └───animal3d
│   └───models
|         └─── SMPL
|         └─── SMAL
│   
└───samples
│   └───denoised
│   └───missing_points
│   └───sample_list
│   └───images
│   └───heatmaps
│   └───training_models
│   └───training_samples
│   └───animal_samples
│   └───animal_images
|
└───best_model
```

The dataset directory will be where all datasets and body models are stored
The samples directory is where all results and trained models are stored
The best_model directory is where the best models should be stored

Although this is only the best practice, it is very easy to change the locations of where items are stored in the arguments.


## Install

### Install Datasets and Models

Installation instruction for body models and datasets can be found [here](/docs/datasets.md)  

### Requirments For Project

The specific python librarys used for the project can be downloaded from requirements.txt
This can be done using [Requirements](/docs/pythonenv.md) 

### Install Best Model 

The best current model can be found at ... and should be stored in /best_model/

## Training

If you want to train your own model then run the code in `main.py`

The parameters can be modified in the config/train.py with these parameters
- 'noisy': Location of the noisy data samples generated by preprocessing
- 'clean': Location of the clean data samples generated by preprocessing
- 'batch_size': How many clean pose files are used at any point in time 
- 'no_samples': How many samples are randomly taken from each file (so the total batch size is batch_size * no_samples)
- 'lr': The learning rate of the optimiser
- 'epochs': The number of epochs used to train the model
- 'samples': The number of arbitray generated poses to make at every 50th epoch
- 'load_model': The model at which to start the training (if starting from nothing set to None)
- 'start_epoch': The epoch that training starts at (default should be 0)
- 'world_size': The amount of GPUs available (leave as default: torch.cuda.device_count(), unless have specific needs)

## Generate Poses

There are several different uses of the model that allow for different generation types.
If you want to generate diverse poses can be found [here](/docs/pose_generation.md)
Examples of how to use any functions can be seen in the `if __name__ == '__main__':` section in any of the files specified

## Animal Generation

If you want to generate diverse animal poses can be found [here](/docs/animal.md)

## Experiments

The way to run different experiments can be found [here](/docs/experiments.md)

# Acknowledgements 

Here are all the other systems that helped:
- [NRDF](https://github.com/hynann/NRDF) Neural Riemannian Distance Fields (specifically useful for the preprocessing step and utilities)
- [VPose](https://github.com/nghorbani/human_body_prior) Help generateing bodies 
- [AMASS](https://amass.is.tue.mpg.de/) The dataset used
- [SMPL](https://smpl.is.tue.mpg.de/) The body used to visualise the data
- [Body Visualiser](https://github.com/nghorbani/body_visualizer) The library to visualise the bodies
- [DiT](https://github.com/facebookresearch/DiT) The transformer architecture used to learn the Vector Fields
- [pytorch3d](https://github.com/facebookresearch/pytorch3d) A library used to convert between axis angles and Rotation matrixes aswell as calculate the exp, log and geodesic distance for the rotation matrixes
